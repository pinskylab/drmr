---
title: "Get Started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{get-started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

First, we load the packages necessary for our analysis.

```{r setup}
library(drmr)
library(sf) ## "mapping"
library(ggplot2) ## graphs
library(bayesplot) ## and more graphs
library(dplyr)
```

Now, we load the data.

```{r data}
map_name <- system.file("maps/sum_fl.shp", package = "drmr")

map <- st_read(map_name)

fmat <-
  system.file("fmat.rds", package = "drmr") |>
  readRDS()

data(sum_fl)
```

## Data processing & splitting

To assess model predictions, the chunk below splits the data into train and
test.

```{r split}
## 5 years-ahead predictions
first_year_forecast <- max(sum_fl$year) - 5

first_id_forecast <-
  first_year_forecast - min(sum_fl$year) + 1

years_all <- seq_len(NCOL(fmat))
years_train <- years_all[years_all < first_id_forecast]
years_test <- years_all[years_all >= first_id_forecast]

## splitting instantaneous fishing mortality rates
f_train <- fmat[, years_train]
f_test  <- fmat[, years_test]

## splitting data
dat_test <- sum_fl |>
  filter(year >= first_year_forecast)

dat_train <- sum_fl |>
  filter(year < first_year_forecast)
```

For improved MCMC efficiency, I will center the explanatory
variables. Specifically, for each variable, I will subtract its mean calculated
during the training period.

```{r centering}
avgs <- c("stemp" = mean(dat_train$stemp),
          "btemp" = mean(dat_train$btemp),
          "depth" = mean(dat_train$depth),
          "lat" = mean(dat_train$lat),
          "lon" = mean(dat_train$lon))

min_year <- dat_train$year |>
  min()

dat_train <- dat_train |>
  mutate(stemp = stemp - avgs["stemp"],
         btemp = btemp - avgs["btemp"],
         depth = depth - avgs["depth"],
         lat   = lat - avgs["lat"],
         lon   = lon - avgs["lon"],
         time  = year - min_year)

dat_test <- dat_test |>
  mutate(stemp = stemp - avgs["stemp"],
         btemp = btemp - avgs["btemp"],
         depth = depth - avgs["depth"],
         lat   = lat - avgs["lat"],
         lon   = lon - avgs["lon"],
         time  = year - min_year)
```

Finally, I transform our response variable into a density.

```{r ytransform}
dat_train <- dat_train |>
  mutate(dens = y / area_km2,
         .before = y)

dat_test <- dat_test |>
  mutate(dens = y / area_km2,
         .before = y)
```

## Preparing data for model fit


This package uses `cmdstanr` to fit DRMs to the data. The data passed to
`cmdstanr` objects is stored in a `list` and we provide a function called
`make_data`. 


The `list` to fit the simplest model possible can be obtained as follows:

```{r make_data_simplest}
data <-
  make_data(y = dat_train$dens,
            time = dat_train$year,
            site = dat_train$patch,
            n_ages = nrow(f_train),
            age_at_maturity = integer(0),
            m = 0.25) # fishing mortality
```

In general, the `make_data` function will control what model we are fitting
through "toggles" and different inputs (type `?make_data` for
documentation). For more information, see the toggles vignette
(`vignettes("toggles", package = "drmr")`).


## Fitting model

The code below loads the object used to fit the DRM models. We don't need to
reload this object if we update the data list using different options from the
`make_data` function.

```{r drm_load}
drm_compiled <-
  instantiate::stan_package_model(name = "drm",
                                  package = "drmr")
```

To get MCMC samples from the posterior, run:

```{r drm_mcmc}
mcmc_samples <-
  drm_compiled$sample(data = data,
                      iter_sampling = 1000,
                      iter_warmup = 1000,
                      chains = 4,
                      parallel_chains = 4)
```
